<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.5"/>
<title>VexCL: Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">VexCL
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.5 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">VexCL Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a href="https://travis-ci.org/ddemidov/vexcl"></a></p>
<p>VexCL is a vector expression template library for OpenCL/CUDA. It has been created for ease of GPGPU development with C++. VexCL strives to reduce amount of boilerplate code needed to develop GPGPU applications. The library provides convenient and intuitive notation for vector arithmetic, reduction, sparse matrix-vector products, etc. Multi-device and even multi-platform computations are supported. The source code of the library is distributed under very permissive MIT license.</p>
<p>The code is available at <a href="https://github.com/ddemidov/vexcl">https://github.com/ddemidov/vexcl</a>.</p>
<p>Doxygen-generated documentation: <a href="http://ddemidov.github.io/vexcl">http://ddemidov.github.io/vexcl</a>.</p>
<p>Slides from VexCL-related talks:</p>
<ul>
<li><a href="https://speakerdeck.com/ddemidov/vexcl-at-meeting-c-plus-plus-2012">Meeting C++ 2012, Dusseldorf</a></li>
<li><a href="https://speakerdeck.com/ddemidov/vexcl-at-cse13">SIAM CSE 2013, Boston</a></li>
<li><a href="https://fosdem.org/2013/schedule/event/odes_cuda_opencl">FOSDEM 2013, Brussels</a></li>
<li><a href="https://speakerdeck.com/ddemidov/converting-generic-c-plus-plus-algorithms-to-opencl-with-vexcl-library">GPU-SMP-2013, Changchun, China</a></li>
<li><a href="https://speakerdeck.com/ddemidov/vexcl-at-pecos-university-of-texas-2013">Overview of VexCL interface, UTexas, Austin, USA</a></li>
<li><a href="https://speakerdeck.com/ddemidov/vexcl-implementation-university-of-texas-2013">VexCL implementation, UTexas, Austin, USA</a></li>
</ul>
<p>The paper <a href="http://arxiv.org/abs/1212.6326">Programming CUDA and OpenCL: A Case Study Using Modern C++ Libraries</a> compares both convenience and performance of several GPGPU libraries, including VexCL.</p>
<h3>Table of contents</h3>
<ul>
<li><a href="#selecting-backend">Selecting backend</a></li>
<li><a href="#context-initialization">Context initialization</a></li>
<li><a href="#memory-allocation">Memory allocation</a></li>
<li><a href="#copies-between-host-and-devices">Copies between host and devices</a></li>
<li><a href="#vector-expressions">Vector expressions</a><ul>
<li><a href="#builtin-operations">Builtin operations</a></li>
<li><a href="#constants">Constants</a></li>
<li><a href="#element-indices">Element indices</a></li>
<li><a href="#user-defined-functions">User-defined functions</a></li>
<li><a href="#tagged-terminals">Tagged terminals</a></li>
<li><a href="#temporary-values">Temporary values</a></li>
<li><a href="#random-number-generation">Random number generation</a></li>
<li><a href="#permutations">Permutations</a></li>
<li><a href="#slicing">Slicing</a></li>
<li><a href="#reducing">Reducing multidimensional expressions</a></li>
<li><a href="#reshaping">Reshaping</a></li>
<li><a href="#mba">Scattered data interpolation with multilevel B-Splines</a></li>
<li><a href="#fast-fourier-transform">Fast Fourier Transform</a></li>
</ul>
</li>
<li><a href="#reductions">Reductions</a></li>
<li><a href="#sparse-matrix-vector-products">Sparse matrix-vector products</a></li>
<li><a href="#stencil-convolutions">Stencil convolutions</a></li>
<li><a href="#raw-pointers">Raw pointers</a></li>
<li><a href="#parallel-primitives">Sort, scan, reduce-by-key algorithms</a></li>
<li><a href="#multivectors">Multivectors</a></li>
<li><a href="#converting-generic-c-algorithms-to-opencl">Converting generic C++ algorithms to OpenCL/CUDA</a><ul>
<li><a href="#kernel-generator">Kernel generator</a></li>
<li><a href="#function-generator">Function generator</a></li>
</ul>
</li>
<li><a href="#custom-kernels">Custom kernels</a></li>
<li><a href="#interoperability-with-other-libraries">Interoperability with other libraries</a></li>
<li><a href="#supported-compilers">Supported compilers</a></li>
</ul>
<h2><a class="anchor" id="selecting-backend"></a>Selecting backend</h2>
<p>VexCL provides two backends: OpenCL and CUDA. In order to choose either of those, user has to define <code>VEXCL_BACKEND_OPENCL</code> or <code>VEXCL_BACKEND_CUDA</code> macros. In case neither of those are defined, OpenCL backend is chosen by default. One also has to link to either libOpenCL.so (OpenCL.dll) or libcuda.so (cuda.dll).</p>
<p>For the CUDA backend to work, CUDA Toolkit has to be installed, NVIDIA CUDA compiler driver <code>nvcc</code> has to be in executable PATH and usable at runtime.</p>
<h2><a class="anchor" id="context-initialization"></a>Context initialization</h2>
<p>VexCL transparently works with multiple compute devices that are present in the system. A VexCL context is initialized with a device filter, which is just a functor that takes a reference to <code>vex::device</code> and returns a <code>bool</code>. Several <a href="http://ddemidov.github.io/vexcl/namespacevex_1_1Filter.html">standard filters</a> are provided, but one can easily add a custom functor. Filters may be combined with logical operators. All compute devices that satisfy the provided filter are added to the created context. In the example below all GPU devices that support double precision arithmetic are selected: </p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;stdexcept&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;<a class="code" href="vexcl_8hpp.html">vexcl/vexcl.hpp</a>&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main() {</div>
<div class="line">    <a class="code" href="classvex_1_1Context.html">vex::Context</a> ctx( <a class="code" href="structvex_1_1Filter_1_1Type.html">vex::Filter::Type</a>(CL_DEVICE_TYPE_GPU) &amp;&amp; vex::Filter::DoublePrecision );</div>
<div class="line"></div>
<div class="line">    <span class="keywordflow">if</span> (!ctx) <span class="keywordflow">throw</span> std::runtime_error(<span class="stringliteral">&quot;No devices available.&quot;</span>);</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Print out list of selected devices:</span></div>
<div class="line">    std::cout &lt;&lt; ctx &lt;&lt; std::endl;</div>
<div class="line">}</div>
</div><!-- fragment --><p>One of the most convenient filters is <code><a class="el" href="namespacevex_1_1Filter.html#ad1123eb70914e1d9efce4b5990a1cb33" title="Environment filter. ">vex::Filter::Env</a></code> which selects compute devices based on environment variables. It allows to switch compute device without need to recompile the program.</p>
<h2><a class="anchor" id="memory-allocation"></a>Memory allocation</h2>
<p>The <code><a class="el" href="classvex_1_1vector.html" title="Device vector. ">vex::vector</a>&lt;T&gt;</code> class constructor accepts a const reference to <code>std::vector&lt;vex::command_queue&gt;</code>. A <code><a class="el" href="classvex_1_1Context.html" title="VexCL context holder. ">vex::Context</a></code> instance may be conveniently converted to this type, but it is also possible to initialize the command queues elsewhere (e.g. with the OpenCL backend <code>vex::command_queue</code> is typedefed to <code>cl::CommandQueue</code>), thus completely eliminating the need to create a <code><a class="el" href="classvex_1_1Context.html" title="VexCL context holder. ">vex::Context</a></code>. Each command queue in the list should uniquely identify a single compute device.</p>
<p>The contents of the created vector will be partitioned across all devices that were present in the queue list. The size of each partition will be proportional to the device bandwidth, which is measured the first time the device is used. All vectors of the same size are guaranteed to be partitioned consistently, which minimizes inter-device communication.</p>
<p>In the example below, three device vectors of the same size are allocated. Vector <code>A</code> is copied from host vector <code>a</code>, and the other vectors are created uninitialized: </p>
<div class="fragment"><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> n = 1024 * 1024;</div>
<div class="line"><a class="code" href="classvex_1_1Context.html">vex::Context</a> ctx( <a class="code" href="namespacevex_1_1Filter.html#a0221a1c47f0b9602316d89e6e28d4ef0">vex::Filter::Any</a> );</div>
<div class="line"></div>
<div class="line">std::vector&lt;double&gt; a(n, 1.0);</div>
<div class="line"></div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> A(ctx, a);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> B(ctx, n);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> C(ctx, n);</div>
</div><!-- fragment --><p> Assuming that the current system has an NVIDIA and an AMD GPUs along with an Intel CPU installed, possible partitioning may look as in the following figure:</p>
<div class="image">
<img src="https://raw.github.com/ddemidov/vexcl/master/doc/figures/partitioning.png"  alt="Partitioning"/>
</div>
<h2><a class="anchor" id="copies-between-host-and-devices"></a>Copies between host and devices</h2>
<p>The function <code><a class="el" href="namespacevex.html#aaa68b032f0d66695e3b3b6c5375e8cf6" title="Copy multivector to host vector. ">vex::copy()</a></code> allows one to copy data between host and device memory spaces. There are two forms of the function &ndash; a simple one and an STL-like one: </p>
<div class="fragment"><div class="line">std::vector&lt;double&gt; h(n);       <span class="comment">// Host vector.</span></div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> d(ctx, n);  <span class="comment">// Device vector.</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Simple form:</span></div>
<div class="line"><a class="code" href="namespacevex.html#aaa68b032f0d66695e3b3b6c5375e8cf6">vex::copy</a>(h, d);    <span class="comment">// Copy data from host to device.</span></div>
<div class="line"><a class="code" href="namespacevex.html#aaa68b032f0d66695e3b3b6c5375e8cf6">vex::copy</a>(d, h);    <span class="comment">// Copy data from device to host.</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// STL-like form:</span></div>
<div class="line"><a class="code" href="namespacevex.html#aaa68b032f0d66695e3b3b6c5375e8cf6">vex::copy</a>(h.begin(), h.end(), d.begin()); <span class="comment">// Copy data from host to device.</span></div>
<div class="line"><a class="code" href="namespacevex.html#aaa68b032f0d66695e3b3b6c5375e8cf6">vex::copy</a>(d.begin(), d.end(), h.begin()); <span class="comment">// Copy data from device to host.</span></div>
</div><!-- fragment --><p>The STL-like variant can copy sub-ranges of the vectors, or copy data from/to raw host pointers.</p>
<p>Vectors also overload the array subscript operator, <code>operator[]</code>, so that users may directly read or write individual vector elements. This operation is highly ineffective and should be used with caution. Iterators allow for element access as well, so that STL algorithms may in principle be used with device vectors. This would be very slow but may be used as a temporary building block.</p>
<p>Another option for host-device data transfer is mapping device memory buffer to a host array. The mapped array then may be transparently read or written. The method <code>vector::map(unsigned d)</code> maps the d-th partition of the vector and returns the mapped array: </p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> X(ctx, N);</div>
<div class="line"><span class="keyword">auto</span> mapped_ptr = X.map(0); <span class="comment">// Unmapped automatically when goes out of scope</span></div>
<div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> i = 0; i &lt; X.part_size(0); ++i)</div>
<div class="line">    mapped_ptr[i] = host_function(i);</div>
</div><!-- fragment --><h2><a class="anchor" id="vector-expressions"></a>Vector expressions</h2>
<p>VexCL allows the use of convenient and intuitive notation for vector operations. In order to be used in the same expression, all vectors have to be <em>compatible</em>:</p>
<ul>
<li>Have same size;</li>
<li>Span same set of compute devices.</li>
</ul>
<p>If these conditions are satisfied, then vectors may be combined with rich set of available expressions. Vector expressions are processed in parallel across all devices they were allocated on. One should keep in mind that in case several command queues are used, then the queues of the vector that is being assigned to will be employed. Each vector expression results in the launch of a single compute kernel. The kernel is automatically generated and launched the first time the expression is encountered in the program. If the <code>VEXCL_SHOW_KERNELS</code> macro is defined, then the sources of all generated kernels will be dumped to the standard output. For example, the expression: </p>
<div class="fragment"><div class="line">X = 2 * Y - <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(Z);</div>
</div><!-- fragment --><p> will lead to the launch of the following compute kernel: </p>
<div class="fragment"><div class="line">kernel <span class="keywordtype">void</span> vexcl_vector_kernel(</div>
<div class="line">    ulong n,</div>
<div class="line">    global <span class="keywordtype">double</span> * prm_1,</div>
<div class="line">    <span class="keywordtype">int</span> prm_2,</div>
<div class="line">    global <span class="keywordtype">double</span> * prm_3,</div>
<div class="line">    global <span class="keywordtype">double</span> * prm_4</div>
<div class="line">)</div>
<div class="line">{</div>
<div class="line">    <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> idx = get_global_id(0); idx &lt; n; idx += get_global_size(0)) {</div>
<div class="line">        prm_1[idx] = ( ( prm_2 * prm_3[idx] ) - <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>( prm_4[idx] ) );</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p> Here and in the rest of examples <code>X</code>, <code>Y</code>, and <code>Z</code> are compatible instances of <code><a class="el" href="classvex_1_1vector.html" title="Device vector. ">vex::vector</a>&lt;double&gt;</code>; it is also assumed that OpenCL backend is selected.</p>
<p>VexCL is able to cache the compiled kernels offline. The compiled binaries are stored in <code>$HOME/.vexcl</code> on Linux and MacOSX, and in <code>APPDATA%\vexcl</code> on Windows systems. In order to enable this functionality for OpenCL backend, the user has to define the <code>VEXCL_CACHE_KERNELS</code> macro. NVIDIA OpenCL implementation does the caching already, but on AMD or Intel platforms this may lead to dramatic decrease of program initialization time (e.g. VexCL tests take around 20 seconds to complete without kernel caches, and 2 seconds when caches are available). In case of the CUDA backend the offline caching is always enabled.</p>
<h3><a class="anchor" id="builtin-operations"></a>Builtin operations</h3>
<p>VexCL expressions may combine device vectors and scalars with arithmetic, logic, or bitwise operators as well as with builtin OpenCL functions. If some builtin operator or function is unavailable, it should be considered a bug. Please do not hesitate to open an issue in this case.</p>
<div class="fragment"><div class="line">Z = <a class="code" href="group__builtins.html#ga58fd7019954df29eaa7be3a78065df7a">sqrt</a>(2 * X) + <a class="code" href="group__builtins.html#ga57b2cd7dfd2f36f085ccb3e927620828">pow</a>(<a class="code" href="group__builtins.html#ga1c4f595ebe70270518a9925ff8c3b22f">cos</a>(Y), 2.0);</div>
</div><!-- fragment --><h3><a class="anchor" id="constants"></a>Constants</h3>
<p>As you have seen above, <code>2</code> in the expression <code>2 * Y - sin(Z)</code> is passed to the generated compute kernel as an <code>int</code> parameter (<code>prm_2</code>). Sometimes this is desired behaviour, because the same kernel will be reused for the expressions <code>42 * Z - sin(Y)</code> or <code>a * Y - sin(Y)</code> (where <code>a</code> is an integer variable). But this may lead to a slight overhead if an expression involves true constant that will always have same value. The macro <code>VEX_CONSTANT</code> allows one to define such constants for use in vector expressions. Compare the generated kernel for the following example with the kernel above: </p>
<div class="fragment"><div class="line"><a class="code" href="constants_8hpp.html#a076ebff70ce67abaffd46155025e2aa4">VEX_CONSTANT</a>(two, 2);</div>
<div class="line"></div>
<div class="line">X = two() * Y - <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(Z);</div>
</div><!-- fragment --><div class="fragment"><div class="line">kernel <span class="keywordtype">void</span> vexcl_vector_kernel(</div>
<div class="line">    ulong n,</div>
<div class="line">    global <span class="keywordtype">double</span> * prm_1,</div>
<div class="line">    global <span class="keywordtype">double</span> * prm_3,</div>
<div class="line">    global <span class="keywordtype">double</span> * prm_4</div>
<div class="line">)</div>
<div class="line">{</div>
<div class="line">    <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> idx = get_global_id(0); idx &lt; n; idx += get_global_size(0)) {</div>
<div class="line">        prm_1[idx] = ( ( ( 2 ) * prm_3[idx] ) - <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>( prm_4[idx] ) );</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>VexCL provides some predefined constants in the <code><a class="el" href="namespacevex_1_1constants.html" title="Mathematical constants. ">vex::constants</a></code> namespace that correspond to boost::math::constants (e.g. <code>vex::constants::pi()</code>).</p>
<h3><a class="anchor" id="element-indices"></a>Element indices</h3>
<p>The function <code><a class="el" href="namespacevex.html#acf35349b5accc05f96b291457f522acb" title="When used in vector expression, returns current element index plus offset. ">vex::element_index</a>(size_t offset = 0)</code> allows one to use the index of each vector element inside vector expressions. The numbering is continuous across the compute devices and starts with an optional <code>offset</code>.</p>
<div class="fragment"><div class="line"><span class="comment">// Linear function:</span></div>
<div class="line"><span class="keywordtype">double</span> x0 = 0.0, dx = 1.0 / (X.size() - 1);</div>
<div class="line">X = x0 + dx * <a class="code" href="namespacevex.html#acf35349b5accc05f96b291457f522acb">vex::element_index</a>();</div>
<div class="line"></div>
<div class="line"><span class="comment">// Single period of sine function:</span></div>
<div class="line">Y = <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(vex::constants::two_pi() * <a class="code" href="namespacevex.html#acf35349b5accc05f96b291457f522acb">vex::element_index</a>() / Y.size());</div>
</div><!-- fragment --><h3><a class="anchor" id="user-defined-functions"></a>User-defined functions</h3>
<p>Users may define custom functions to use in vector expressions. One has to define the function signature and function body. The body may contain any number of lines of valid OpenCL or CUDA code, depending on the selected backend. Function parameters are named <code>prm1</code>, <code>prm2</code>, etc. The most convenient way to define a function is via the <code>VEX_FUNCTION</code> macro:</p>
<div class="fragment"><div class="line"><a class="code" href="operations_8hpp.html#aff85c71f5e6716591cf5948f92e093b3">VEX_FUNCTION</a>(squared_radius, <span class="keywordtype">double</span>(<span class="keywordtype">double</span>, <span class="keywordtype">double</span>), <span class="stringliteral">&quot;return prm1 * prm1 + prm2 * prm2;&quot;</span>);</div>
<div class="line">Z = <a class="code" href="group__builtins.html#ga58fd7019954df29eaa7be3a78065df7a">sqrt</a>(squared_radius(X, Y));</div>
</div><!-- fragment --><p> The resulting <code>squared_radius</code> function object is stateless; only its type is used for kernel generation. Hence, it is safe to put commonly used functions in global scope.</p>
<p>Note that any valid vector expression may be passed as a function parameter: </p>
<div class="fragment"><div class="line">Z = squared_radius(<a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(X + Y), <a class="code" href="group__builtins.html#ga1c4f595ebe70270518a9925ff8c3b22f">cos</a>(X - Y));</div>
</div><!-- fragment --><p>Custom functions may be used not only for convenience, but also for performance reasons. The above example could in principle be rewritten as: </p>
<div class="fragment"><div class="line">Z = <a class="code" href="group__builtins.html#ga58fd7019954df29eaa7be3a78065df7a">sqrt</a>(X * X + Y * Y);</div>
</div><!-- fragment --><p> The drawback of the latter variant is that <code>X</code> and <code>Y</code> will be read <em>twice</em>.</p>
<p>The convenience macro <code>VEX_STRINGIZE_SOURCE</code> may be used to easily enquote the source code for a user-defined function. It's advantage is that users will have benefits of syntax highlighting and general readability of their code: </p>
<div class="fragment"><div class="line"><a class="code" href="operations_8hpp.html#aff85c71f5e6716591cf5948f92e093b3">VEX_FUNCTION</a>(diff_cube, <span class="keywordtype">double</span>(<span class="keywordtype">double</span>, <span class="keywordtype">double</span>),</div>
<div class="line">    <a class="code" href="operations_8hpp.html#a8c4fa42e03a69b51b7e1af1c59a9a3b9">VEX_STRINGIZE_SOURCE</a>(</div>
<div class="line">        <span class="keywordtype">double</span> d = prm1 - prm2;</div>
<div class="line">        <span class="keywordflow">return</span> d * d * d;</div>
<div class="line">        )</div>
<div class="line">    );</div>
</div><!-- fragment --><h3><a class="anchor" id="tagged-terminals"></a>Tagged terminals</h3>
<p>The code snippet from the last paragraph is ineffective because the compiler cannot tell if any two terminals in an expression tree are actually referring to the same data. But programmers often have this information. VexCL allows one to pass this knowledge to compiler by tagging terminals with unique tags. By doing this, the programmer guarantees that any two terminals with matching tags are referencing same data.</p>
<p>Below is a more effective variant of the above example: </p>
<div class="fragment"><div class="line"><span class="keyword">using</span> <a class="code" href="namespacevex.html#a31259ad9c0db468f3f73e1decf8d0c14">vex::tag</a>;</div>
<div class="line">Z = <a class="code" href="group__builtins.html#ga58fd7019954df29eaa7be3a78065df7a">sqrt</a>(tag&lt;1&gt;(X) * tag&lt;1&gt;(X) + tag&lt;2&gt;(Y) * tag&lt;2&gt;(Y));</div>
</div><!-- fragment --><p> Here, the generated kernel will have one parameter for each of the vectors <code>X</code> and <code>Y</code>.</p>
<h3><a class="anchor" id="temporary-values"></a>Temporary values</h3>
<p>Some expressions may have several occurences of the same subexpression. Unfortunately, VexCL is not able to determine these cases without the programmer's help. For example, let's look at the following expression: </p>
<div class="fragment"><div class="line">Y = <a class="code" href="group__builtins.html#ga3724c8eb690307d679f1914384b7d137">log</a>(X) * (<a class="code" href="group__builtins.html#ga3724c8eb690307d679f1914384b7d137">log</a>(X) + Z);</div>
</div><!-- fragment --><p> Here, <code>log(X)</code> would be computed twice. One could tag vector <code>X</code> as in: </p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> x = vex::tag&lt;1&gt;(X);</div>
<div class="line">Y = <a class="code" href="group__builtins.html#ga3724c8eb690307d679f1914384b7d137">log</a>(x) * (<a class="code" href="group__builtins.html#ga3724c8eb690307d679f1914384b7d137">log</a>(x) + Z);</div>
</div><!-- fragment --><p>and hope that the backend compiler is smart enough to reuse result of <code>log(x)</code> (e.g. NVIDIA's compiler <em>is</em> smart enough to do this). But it is also possible to explicitly ask VexCL to store result of a subexpression in a local variable and reuse it. The <code><a class="el" href="namespacevex.html#ae1e84dcac8995e5fbfb0cc2848d94297" title="Create temporary to be reused in a vector expression. ">vex::make_temp()</a></code> function template serves this purpose:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> tmp1 = vex::make_temp&lt;1&gt;( <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(X) );</div>
<div class="line"><span class="keyword">auto</span> tmp2 = vex::make_temp&lt;2&gt;( <a class="code" href="group__builtins.html#ga1c4f595ebe70270518a9925ff8c3b22f">cos</a>(X) );</div>
<div class="line">Y = (tmp1 - tmp2) * (tmp1 + tmp2);</div>
</div><!-- fragment --><p>Any valid vector or multivector expression (but not additive expressions, such as sparse matrix-vector products) may be wrapped into a <code><a class="el" href="namespacevex.html#ae1e84dcac8995e5fbfb0cc2848d94297" title="Create temporary to be reused in a vector expression. ">make_temp()</a></code> call.</p>
<h3><a class="anchor" id="random-number-generation"></a>Random number generation</h3>
<p>VexCL provides a counter-based random number generators from <a href="http://www.deshawresearch.com/resources_random123.html">Random123</a> suite, in which Nth random number is obtained by applying a stateless mixing function to N instead of the conventional approach of using N iterations of a stateful transformation. This technique is easily parallelizable and is well suited for use in GPGPU applications.</p>
<p>For integral types, the generated values span the complete range; for floating point types, the generated values lie in the interval [0,1].</p>
<p>In order to use a random number sequence in a vector expression, the user has to declare an instance of either <code><a class="el" href="structvex_1_1Random.html" title="A random generator. ">vex::Random</a></code> or <code><a class="el" href="structvex_1_1RandomNormal.html" title="Returns normal distributed random numbers. ">vex::RandomNormal</a></code> class template as in the following example: </p>
<div class="fragment"><div class="line"><a class="code" href="structvex_1_1Random.html">vex::Random&lt;double, vex::random::threefry&gt;</a> rnd;</div>
<div class="line"></div>
<div class="line"><span class="comment">// X will contain random numbers from [-1, 1]:</span></div>
<div class="line">X = 2 * rnd(<a class="code" href="namespacevex.html#acf35349b5accc05f96b291457f522acb">vex::element_index</a>(), std::rand()) - 1;</div>
</div><!-- fragment --><p> Note that <code><a class="el" href="namespacevex.html#acf35349b5accc05f96b291457f522acb" title="When used in vector expression, returns current element index plus offset. ">vex::element_index()</a></code> here provides the random number generator with a sequence position N.</p>
<h3><a class="anchor" id="permutations"></a>Permutations</h3>
<p><code><a class="el" href="namespacevex.html#a1d8048e3bb5185ab018e9d0a0649ef0b" title="Returns permutation functor which is based on an integral expression. ">vex::permutation()</a></code> allows the use of a permuted vector in a vector expression. The function accepts a vector expression that returns integral values (indices). The following example reverses <code>X</code> and assigns it to <code>Y</code>:</p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;size_t&gt;</a> I(ctx, N);</div>
<div class="line">I = N - 1 - <a class="code" href="namespacevex.html#acf35349b5accc05f96b291457f522acb">vex::element_index</a>();</div>
<div class="line"><span class="keyword">auto</span> reverse = <a class="code" href="namespacevex.html#a1d8048e3bb5185ab018e9d0a0649ef0b">vex::permutation</a>(I)</div>
<div class="line"></div>
<div class="line">Y = reverse(X);</div>
</div><!-- fragment --><p>The drawback of the above approach is that you have to store and access an index vector. Sometimes this is a necessary evil, but in this simple example we can do better. In the following snippet a lightweight expression is used to construct the same permutation:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> reverse = <a class="code" href="namespacevex.html#a1d8048e3bb5185ab018e9d0a0649ef0b">vex::permutation</a>( N - 1 - <a class="code" href="namespacevex.html#acf35349b5accc05f96b291457f522acb">vex::element_index</a>() );</div>
<div class="line">Y = reverse(X);</div>
</div><!-- fragment --><p>Note that any valid vector expression may be used as an index, including user-defined functions.</p>
<p><em>Permutation operations are only supported in single-device contexts.</em></p>
<h3><a class="anchor" id="slicing"></a>Slicing</h3>
<p>An instance of the <code><a class="el" href="structvex_1_1slicer.html" title="Slicing operator. ">vex::slicer</a>&lt;NDIM&gt;</code> class allows one to conveniently access sub-blocks of multi-dimensional arrays that are stored in <code><a class="el" href="classvex_1_1vector.html" title="Device vector. ">vex::vector</a></code> in row-major order. The constructor of the class accepts the dimensions of the array to be sliced. The following example extracts every other element from interval <code>[100, 200)</code> of a one-dimensional vector X:</p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> X(ctx, n);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> Y(ctx, 50);</div>
<div class="line"></div>
<div class="line"><a class="code" href="structvex_1_1slicer.html">vex::slicer&lt;1&gt;</a> slice({n});</div>
<div class="line"></div>
<div class="line">Y = slice[<a class="code" href="structvex_1_1range.html">vex::range</a>(100, 2, 200)](X);</div>
</div><!-- fragment --><p>And the example below shows how to work with a two-dimensional matrix:</p>
<div class="fragment"><div class="line"><span class="keyword">using</span> <a class="code" href="structvex_1_1range.html">vex::range</a>;</div>
<div class="line"></div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> X(ctx, n * n); <span class="comment">// n-by-n matrix stored in row-major order.</span></div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> Y(ctx, n);</div>
<div class="line"></div>
<div class="line"><span class="comment">// vex::extents is a helper object similar to boost::multi_array::extents</span></div>
<div class="line"><a class="code" href="structvex_1_1slicer.html">vex::slicer&lt;2&gt;</a> slice(<a class="code" href="namespacevex.html#ad713fa361047b676e76f2f2d3342dcdd">vex::extents</a>[n][n]);</div>
<div class="line"></div>
<div class="line">Y = slice[42](X);          <span class="comment">// Put 42-nd row of X into Y.</span></div>
<div class="line">Y = slice[range()][42](X); <span class="comment">// Put 42-nd column of X into Y.</span></div>
<div class="line"></div>
<div class="line">slice[range()][10](X) = Y; <span class="comment">// Put Y into 10-th column of X.</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Assign sub-block [10,20)x[30,40) of X to Z:</span></div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> Z = slice[range(10, 20)][range(30, 40)](X);</div>
<div class="line">assert(Z.size() == 100);</div>
</div><!-- fragment --><p><em>Slicing is only supported in single-device contexts.</em></p>
<h3><a class="anchor" id="reducing"></a>Reducing multidimensional expressions</h3>
<p><code><a class="el" href="namespacevex.html#ab9f2a40c6b7a0f4b540ba12f2b52532b" title="Reduce vex::multi_array along the specified dimensions. ">vex::reduce()</a></code> function allows one to reduce a multidimensional expression along one or more dimensions. The result is again a vector expression. The supported reduction operations are <code>SUM</code>, <code>MIN</code>, and <code>MAX</code>. The function takes three arguments: the shape of the expression to reduce (with the slowest changing dimension in the front), the expression to reduce, and the dimension(s) to reduce along. The latter are specified as indices into the shape array.</p>
<p>In the following example we find maximum absolute value of each row in a two-dimensional matrix and assign the result to a vector: </p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> A(ctx, N * M);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> x(ctx, N);</div>
<div class="line"></div>
<div class="line">x = vex::reduce&lt;vex::MAX&gt;(<a class="code" href="namespacevex.html#ad713fa361047b676e76f2f2d3342dcdd">vex::extents</a>[N][M], <a class="code" href="group__builtins.html#ga58c41dd88675f3e2b70d70190a8980ff">fabs</a>(A), vex::extents[1]);</div>
</div><!-- fragment --><p><em>Expression reduction is only supported in single-device contexts.</em></p>
<h3><a class="anchor" id="reshaping"></a>Reshaping</h3>
<p><code>vex::reshape(expr, dst_dims, src_dims)</code> function is a powerful primitive that allows one to conveniently manipulate multidimensional data. It takes three arguments &ndash; an arbitrary vector expression <code>expr</code> to reshape, the dimensions <code>dst_dims</code> of the final result (with the slowest changing dimension in the front), and the dimensions <code>src_dims</code> of the expression, which are specified as indices into <code>dst_dims</code>. The function returns a vector expression that could be assigned to a vector or participate in a larger expression. The dimensions may be conveniently specified with help of <code><a class="el" href="namespacevex.html#ad713fa361047b676e76f2f2d3342dcdd" title="Helper object for specifying slicer dimensions. ">vex::extents</a></code> object.</p>
<p>Here is an example of transposing a two-dimensional matrix of size NxM: </p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> A(ctx, N * M);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> B = <a class="code" href="namespacevex.html#a159a23f567b28d7d284fa0cd720e900a">vex::reshape</a>(A,</div>
<div class="line">                            vex::extents[M][N], <span class="comment">// new shape</span></div>
<div class="line">                            vex::extents[1][0]  <span class="comment">// A is shaped as [N][M]</span></div>
<div class="line">                            );</div>
</div><!-- fragment --><p>If the source expression lacks some of the destination dimensions, then those will be introduced by replicating the available data. For example, to make a two-dimensional matrix from a one-dimensional vector by copying the vector to each row of the matrix, one could do the following: </p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> x(ctx, N);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> y(ctx, M);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> A(ctx, M * N);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Copy x into rows of A:</span></div>
<div class="line">A = <a class="code" href="namespacevex.html#a159a23f567b28d7d284fa0cd720e900a">vex::reshape</a>(x, vex::extents[M][N], vex::extents[1]);</div>
<div class="line"><span class="comment">// Now, copy y into columns of A:</span></div>
<div class="line">A = <a class="code" href="namespacevex.html#a159a23f567b28d7d284fa0cd720e900a">vex::reshape</a>(x, vex::extents[M][N], vex::extents[0]);</div>
</div><!-- fragment --><p>Here is a more realistic example of a dense matrix-matrix multiplication. Elements of a matrix product <code>C = A * B</code> are defined as <code>C[i][j] = sum_k(A[i][k] * B[k][j])</code>. Let's assume that matrix <code>A</code> has shape <code>[N][L]</code>, and matrix <code>B</code> is shaped as <code>[L][M]</code>. Then matrix <code>C</code> has dimensions <code>[N][M]</code>. In order to implement the multiplication we extend matrices <code>A</code> and <code>B</code> to the shape of <code>[N][L][M]</code>, multiply the resulting expressions, and reduce the product along the middle dimension <code>L</code>: </p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> A(ctx, N * L);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> B(ctx, L * M);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> C(ctx, N * M);</div>
<div class="line"></div>
<div class="line">C = vex::reduce&lt;vex::SUM&gt;(</div>
<div class="line">        vex::extents[N][L][M],</div>
<div class="line">        <a class="code" href="namespacevex.html#a159a23f567b28d7d284fa0cd720e900a">vex::reshape</a>(A, vex::extents[N][L][M], vex::extents[0][1]) *</div>
<div class="line">        <a class="code" href="namespacevex.html#a159a23f567b28d7d284fa0cd720e900a">vex::reshape</a>(B, vex::extents[N][L][M], vex::extents[1][2]),</div>
<div class="line">        1</div>
<div class="line">        );</div>
</div><!-- fragment --><p>This of course would not be as efficient as a carefully crafted custom implementation or a call to a vendor BLAS function. Still, the fact that the result is a vector expression (and hence may be a part of a still larger expression) could be more important sometimes.</p>
<p><em>Reshaping is only supported in single-device contexts.</em></p>
<h3><a class="anchor" id="mba"></a>Scattered data interpolation with multilevel B-Splines</h3>
<p>VexCL provides an implementation of the MBA algorithm based on paper by Lee, Wolberg, and Shin ([S. Lee, G. Wolberg, and S. Y. Shin. Scattered data interpolation with multilevel B-Splines. IEEE Transactions on Visualization and Computer Graphics, 3:228–244, 1997][bsplines]). This is a fast algorithm for scattered N-dimensional data interpolation and approximation. Multilevel B-splines are used to compute a C2-continuously differentiable surface through a set of irregularly spaced points. The algorithm makes use of a coarse-to-fine hierarchy of control lattices to generate a sequence of bicubic B-spline functions whose sum approaches the desired interpolation function. Large performance gains are realized by using B-spline refinement to reduce the sum of these functions into one equivalent B-spline function. High-fidelity reconstruction is possible from a selected set of sparse and irregular samples.</p>
<p>The algorithm is first prepared on a CPU. After that, it may be used in vector expressions. Here is an example in 2D: </p>
<div class="fragment"><div class="line"><span class="comment">// Coordinates of data points:</span></div>
<div class="line">std::vector&lt; std::array&lt;double,2&gt; &gt; coords = {</div>
<div class="line">    {0.0, 0.0},</div>
<div class="line">    {0.0, 1.0},</div>
<div class="line">    {1.0, 0.0},</div>
<div class="line">    {1.0, 1.0},</div>
<div class="line">    {0.4, 0.4},</div>
<div class="line">    {0.6, 0.6}</div>
<div class="line">};</div>
<div class="line"></div>
<div class="line"><span class="comment">// Data values:</span></div>
<div class="line">std::vector&lt;double&gt; values = {</div>
<div class="line">    0.2, 0.0, 0.0, -0.2, -1.0, 1.0</div>
<div class="line">};</div>
<div class="line"></div>
<div class="line"><span class="comment">// Bounding box:</span></div>
<div class="line">std::array&lt;double, 2&gt; xmin = {-0.01, -0.01};</div>
<div class="line">std::array&lt;double, 2&gt; xmax = { 1.01,  1.01};</div>
<div class="line"></div>
<div class="line"><span class="comment">// Initial grid size:</span></div>
<div class="line">std::array&lt;size_t, 2&gt; grid = {5, 5};</div>
<div class="line"></div>
<div class="line"><span class="comment">// Algorithm setup.</span></div>
<div class="line"><a class="code" href="classvex_1_1mba.html">vex::mba&lt;2&gt;</a> surf(ctx, xmin, xmax, coords, values, grid);</div>
<div class="line"></div>
<div class="line"><span class="comment">// x and y are coordinates of arbitrary 2D points:</span></div>
<div class="line"><span class="comment">// vex::vector&lt;double&gt; x, y, z;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Get interpolated values:</span></div>
<div class="line">z = surf(x, y);</div>
</div><!-- fragment --><h3><a class="anchor" id="fast-fourier-transform"></a>Fast Fourier Transform</h3>
<p>VexCL provides an implementation of the Fast Fourier Transform (FFT) that accepts arbitrary vector expressions as input, allows one to perform multidimensional transforms (of any number of dimensions), and supports arbitrary sized vectors:</p>
<div class="fragment"><div class="line"><a class="code" href="structvex_1_1FFT.html">vex::FFT&lt;double, cl_double2&gt;</a> fft(ctx, n);</div>
<div class="line"><a class="code" href="structvex_1_1FFT.html">vex::FFT&lt;cl_double2, double&gt;</a> ifft(ctx, n, vex::fft::inverse);</div>
<div class="line"></div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> rhs(ctx, n), u(ctx, n), K(ctx, n);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Solve Poisson equation with FFT:</span></div>
<div class="line">u = ifft( K * fft(rhs) );</div>
</div><!-- fragment --><p>The restriction of the FFT is that it currently only supports contexts with a single compute device.</p>
<h2><a class="anchor" id="reductions"></a>Reductions</h2>
<p>An instance of <code><a class="el" href="classvex_1_1Reductor.html" title="Parallel reduction of arbitrary expression. ">vex::Reductor</a>&lt;T, OP&gt;</code> allows one to reduce an arbitrary vector expression to a single value of type T. Supported reduction operations are <code>SUM</code>, <code>MIN</code>, and <code>MAX</code>. Reductor objects receive a list of command queues at construction and should only be applied to vectors residing on the same compute devices.</p>
<p>In the following example an inner product of two vectors is computed: </p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1Reductor.html">vex::Reductor&lt;double, vex::SUM&gt;</a> sum(ctx);</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">double</span> s = sum(x * y);</div>
</div><!-- fragment --><p> And here is an easy way to compute an approximate value of π with Monte-Carlo method: </p>
<div class="fragment"><div class="line"><a class="code" href="operations_8hpp.html#aff85c71f5e6716591cf5948f92e093b3">VEX_FUNCTION</a>(squared_radius, <span class="keywordtype">double</span>(<span class="keywordtype">double</span>, <span class="keywordtype">double</span>), <span class="stringliteral">&quot;return prm1 * prm1 + prm2 * prm2;&quot;</span>);</div>
<div class="line"></div>
<div class="line"><a class="code" href="classvex_1_1Reductor.html">vex::Reductor&lt;size_t, vex::SUM&gt;</a> sum(ctx);</div>
<div class="line"><a class="code" href="structvex_1_1Random.html">vex::Random&lt;double, vex::random::threefry&gt;</a> rnd;</div>
<div class="line"></div>
<div class="line">X = 2 * rnd(<a class="code" href="namespacevex.html#acf35349b5accc05f96b291457f522acb">vex::element_index</a>(), std::rand()) - 1;</div>
<div class="line">Y = 2 * rnd(<a class="code" href="namespacevex.html#acf35349b5accc05f96b291457f522acb">vex::element_index</a>(), std::rand()) - 1;</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">double</span> pi = 4.0 * sum(squared_radius(X, Y) &lt; 1) / X.size();</div>
</div><!-- fragment --><h2><a class="anchor" id="sparse-matrix-vector-products"></a>Sparse matrix-vector products</h2>
<p>One of the most common operations in linear algebra is matrix-vector multiplication. An instance of <code><a class="el" href="classvex_1_1SpMat.html" title="Sparse matrix in hybrid ELL-CSR format. ">vex::SpMat</a></code> class holds a representation of a sparse matrix. Its constructor accepts a sparse matrix in common <a href="http://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_.28CSR_or_CRS.29">CRS</a> format. In the example below a <code><a class="el" href="classvex_1_1SpMat.html" title="Sparse matrix in hybrid ELL-CSR format. ">vex::SpMat</a></code> is constructed from an <a href="http://eigen.tuxfamily.org/">Eigen</a> <a href="http://eigen.tuxfamily.org/dox/TutorialSparse.html">sparse matrix</a>:</p>
<div class="fragment"><div class="line">Eigen::SparseMatrix&lt;double, Eigen::RowMajor, int&gt; E;</div>
<div class="line"></div>
<div class="line"><a class="code" href="classvex_1_1SpMat.html">vex::SpMat&lt;double, int&gt;</a> A(ctx, E.rows(), E.cols(),</div>
<div class="line">    E.outerIndexPtr(), E.innerIndexPtr(), E.valuesPtr());</div>
</div><!-- fragment --><p>Matrix-vector products may be used in vector expressions. The only restriction is that the expressions have to be additive. This is due to the fact that the matrix representation may span several compute devices. Hence, a matrix-vector product operation may require several kernel launches and inter-device communication.</p>
<div class="fragment"><div class="line"><span class="comment">// Compute residual value for a system of linear equations:</span></div>
<div class="line">Z = Y - A * X;</div>
</div><!-- fragment --><p>This restriction may be lifted for single-device contexts. In this case VexCL does not need to worry about inter-device communication. Hence, it is possible to inline matrix-vector product into a normal vector expression with the help of <code><a class="el" href="namespacevex.html#aa04547c51b46e0005b37ad00493f7354" title="Inlines a sparse matrix - vector product. ">vex::make_inline()</a></code>:</p>
<div class="fragment"><div class="line">residual = sum(Y - <a class="code" href="namespacevex.html#aa04547c51b46e0005b37ad00493f7354">vex::make_inline</a>(A * X));</div>
<div class="line">Z = <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(<a class="code" href="namespacevex.html#aa04547c51b46e0005b37ad00493f7354">vex::make_inline</a>(A * X));</div>
</div><!-- fragment --><h2><a class="anchor" id="stencil-convolutions"></a>Stencil convolutions</h2>
<p>Stencil convolution is another common operation that may be used, for example, to represent a signal filter, or a (one-dimensional) differential operator. VexCL implements two stencil kinds. The first one is a simple linear stencil that holds linear combination coefficients. The example below computes the moving average of a vector with a 5-point window: </p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1stencil.html">vex::stencil&lt;double&gt;</a> S(ctx, <span class="comment">/*coefficients:*/</span>{0.2, 0.2, 0.2, 0.2, 0.2}, <span class="comment">/*center:*/</span>2);</div>
<div class="line"></div>
<div class="line">Y = X * S;</div>
</div><!-- fragment --><p>Users may also define custom stencil operators. This may be of use if, for example, the operator is nonlinear. The definition of a stencil operator looks very similar to a definition of a custom function. The only difference is that the stencil operator constructor accepts a vector of command queues. The following example implements the nonlinear operator <code>y(i) = sin(x(i) - x(i - 1)) + sin(x(i+1) - sin(x(i))</code>: </p>
<div class="fragment"><div class="line"><a class="code" href="stencil_8hpp.html#a48de2489c51353e5e84a0e23f4b945c9">VEX_STENCIL_OPERATOR</a>(S, <span class="comment">/*return type:*/</span><span class="keywordtype">double</span>, <span class="comment">/*window width:*/</span>3, <span class="comment">/*center:*/</span>1,</div>
<div class="line">    <span class="stringliteral">&quot;return sin(X[0] - X[-1]) + sin(X[1] - X[0]);&quot;</span>, ctx);</div>
<div class="line"></div>
<div class="line">Z = S(Y);</div>
</div><!-- fragment --><p>The current window is available inside the body of the operator through the <code>X</code> array, which is indexed relative to the stencil center.</p>
<p>Stencil convolution operations, similar to the matrix-vector products, are only allowed in additive expressions.</p>
<h2><a class="anchor" id="raw-pointers"></a>Raw pointers</h2>
<p>Unfortunately, describing two dimensional stencils (e.g. discretization of the Laplace operator) would not be effective, because the stencil width would be too large. One can solve this problem by using a combination of <code>raw_pointer(const vector&lt;T&gt;&amp;)</code> with a derefence operator (essentially doing pointer arithmetic inside compute kernel). For the sake of simplicity, the example below implements a simple 3-point laplace operator for a one-dimensional vector; but this could be easily extended in the two-dimensional case: </p>
<div class="fragment"><div class="line"><a class="code" href="constants_8hpp.html#a076ebff70ce67abaffd46155025e2aa4">VEX_CONSTANT</a>(zero, 0);</div>
<div class="line"><a class="code" href="constants_8hpp.html#a076ebff70ce67abaffd46155025e2aa4">VEX_CONSTANT</a>(one,  1);</div>
<div class="line"><a class="code" href="constants_8hpp.html#a076ebff70ce67abaffd46155025e2aa4">VEX_CONSTANT</a>(two,  2);</div>
<div class="line"></div>
<div class="line"><span class="keyword">auto</span> N   = vex::tag&lt;1&gt;( x.size() );</div>
<div class="line"><span class="keyword">auto</span> ptr = vex::tag&lt;2&gt;( <a class="code" href="namespacevex.html#afca1d21b77d4ea7494aa032c9bb81db8">vex::raw_pointer</a>(x) );</div>
<div class="line"></div>
<div class="line"><span class="keyword">auto</span> i     = vex::make_temp&lt;1&gt;( <a class="code" href="namespacevex.html#acf35349b5accc05f96b291457f522acb">vex::element_index</a>() );</div>
<div class="line"><span class="keyword">auto</span> left  = vex::make_temp&lt;2&gt;( if_else(i &gt; zero(),    i - one(), i) );</div>
<div class="line"><span class="keyword">auto</span> right = vex::make_temp&lt;3&gt;( if_else(i + one() &lt; N, i + one(), i) );</div>
<div class="line"></div>
<div class="line">y = *(ptr + i) * two() - *(ptr + left) - *(ptr + right);</div>
</div><!-- fragment --><p>This would result in the following compute kernel: </p>
<div class="fragment"><div class="line">kernel <span class="keywordtype">void</span> vexcl_vector_kernel(</div>
<div class="line">    ulong n,</div>
<div class="line">    global <span class="keywordtype">double</span> * prm_1,</div>
<div class="line">    global <span class="keywordtype">double</span> * prm_2,</div>
<div class="line">    ulong prm_3,</div>
<div class="line">    ulong prm_4</div>
<div class="line">)</div>
<div class="line">{</div>
<div class="line">    <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> idx = get_global_id(0); idx &lt; n; idx += get_global_size(0)) {</div>
<div class="line">        ulong temp_1 = prm_3 + idx;</div>
<div class="line">        ulong temp_2 = temp_1 &gt; 0 ? temp_1 - 1 : temp_1;</div>
<div class="line">        ulong temp_3 = temp_1 + 1 &lt; prm_4 ? temp_1 + 1 : temp_1;</div>
<div class="line">        prm_1[idx] = *(prm_2 + temp_1) * 2 - *(prm_2 + temp_2) - *(prm_2 + temp_3);</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>The same approach could be used, for example, to implement an N-body problem with a user-defined function: </p>
<div class="fragment"><div class="line"><span class="comment">// Takes vector size, current element position, and pointer to a vector to sum:</span></div>
<div class="line"><a class="code" href="operations_8hpp.html#aff85c71f5e6716591cf5948f92e093b3">VEX_FUNCTION</a>(global_interaction, <span class="keywordtype">double</span>(<span class="keywordtype">size_t</span>, <span class="keywordtype">size_t</span>, <span class="keywordtype">double</span>*),</div>
<div class="line">    <a class="code" href="operations_8hpp.html#a8c4fa42e03a69b51b7e1af1c59a9a3b9">VEX_STRINGIZE_SOURCE</a>(</div>
<div class="line">        <span class="keywordtype">double</span> sum = 0;</div>
<div class="line">        <span class="keywordtype">double</span> myval = prm3[prm2];</div>
<div class="line">        <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> i = 0; i &lt; prm1; ++i)</div>
<div class="line">            <span class="keywordflow">if</span> (i != prm2) sum += <a class="code" href="group__builtins.html#ga58c41dd88675f3e2b70d70190a8980ff">fabs</a>(prm3[i] - myval);</div>
<div class="line">        <span class="keywordflow">return</span> sum;</div>
<div class="line">        )</div>
<div class="line">    );</div>
<div class="line"></div>
<div class="line">y = global_interaction(x.size(), <a class="code" href="namespacevex.html#acf35349b5accc05f96b291457f522acb">vex::element_index</a>(), <a class="code" href="namespacevex.html#afca1d21b77d4ea7494aa032c9bb81db8">vex::raw_pointer</a>(x));</div>
</div><!-- fragment --><p>Note that the use of <code><a class="el" href="namespacevex.html#afca1d21b77d4ea7494aa032c9bb81db8" title="Cast vex::vector to a raw pointer. ">raw_pointer()</a></code> is limited to single-device contexts for obvious reasons.</p>
<h2><a class="anchor" id="parallel-primitives"></a>Sort, scan, reduce-by-key algorithms</h2>
<p>VexCL provides several standalone parallel primitives that may not be used as part of a vector expression. These are <code>inclusive_scan</code>, <code>exclusive_scan</code>, <code>sort</code>, <code>sort_by_key</code>, <code>reduce_by_key</code>. All of these functions take VexCL vectors as both input and output parameters.</p>
<p>Sorting and scan functions take an optional function object used for comparison and summing of elements. The functor should provide the same interface as, e.g. <code>std::less</code> for sorting or <code>std::plus</code> for summing; additionally, it should provide a VexCL function for device-side operations.</p>
<p>Here is an example of such an object comparing integer elements in such a way that even elements precede odd ones: </p>
<div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="line"><span class="keyword">struct </span>even_first {</div>
<div class="line">    <a class="code" href="operations_8hpp.html#aff85c71f5e6716591cf5948f92e093b3">VEX_FUNCTION</a>(device, <span class="keywordtype">bool</span>(<span class="keywordtype">int</span>, <span class="keywordtype">int</span>),</div>
<div class="line">        <a class="code" href="operations_8hpp.html#a8c4fa42e03a69b51b7e1af1c59a9a3b9">VEX_STRINGIZE_SOURCE</a>(</div>
<div class="line">            <span class="keywordtype">char</span> bit1 = 1 &amp; prm1;</div>
<div class="line">            <span class="keywordtype">char</span> bit2 = 1 &amp; prm2;</div>
<div class="line">            <span class="keywordflow">if</span> (bit1 == bit2) <span class="keywordflow">return</span> prm1 &lt; prm2;</div>
<div class="line">            <span class="keywordflow">return</span> bit1 &lt; bit2;</div>
<div class="line">            )</div>
<div class="line">        );</div>
<div class="line">    <span class="keywordtype">bool</span> operator()(<span class="keywordtype">int</span> a, <span class="keywordtype">int</span> b)<span class="keyword"> const </span>{</div>
<div class="line">        <span class="keywordtype">char</span> bit1 = 1 &amp; a;</div>
<div class="line">        <span class="keywordtype">char</span> bit2 = 1 &amp; b;</div>
<div class="line">        <span class="keywordflow">if</span> (bit1 == bit2) <span class="keywordflow">return</span> a &lt; b;</div>
<div class="line">        <span class="keywordflow">return</span> bit1 &lt; bit2;</div>
<div class="line">    }</div>
<div class="line">};</div>
</div><!-- fragment --><p>Note that VexCL already provides <code><a class="el" href="structvex_1_1less.html" title="Function object class for less-than inequality comparison. ">vex::less</a>&lt;T&gt;</code>, <code><a class="el" href="structvex_1_1less__equal.html" title="Function object class for less-than-or-equal inequality comparison. ">vex::less_equal</a>&lt;T&gt;</code>, <code><a class="el" href="structvex_1_1greater.html" title="Function object class for greater-than inequality comparison. ">vex::greater</a>&lt;T&gt;</code>, <code><a class="el" href="structvex_1_1greater__equal.html" title="Function object class for greater-than-or-equal inequality comparison. ">vex::greater_equal</a>&lt;T&gt;</code>, and <code><a class="el" href="structvex_1_1plus.html" title="Binary function object class whose call returns the result of adding its two arguments. ">vex::plus</a>&lt;T&gt;</code>.</p>
<p>The need to provide both host-side and device-side parts of the functor comes from the fact that multidevice vectors are first sorted partially on each of the compute devices they are allocated on and then merged on the host.</p>
<p>Sorting algorithms may also take tuples of keys/values (in fact, any Boost.Fusion sequence will do). One will have to explicitly specify the comparison functor in this case. Both host and device variants of the comparison functor should take <code>2n</code> arguments, where <code>n</code> is the number of keys. The first <code>n</code> arguments correspond to the left set of keys, and the second <code>n</code> arguments correspond to the right set of keys. Here is an example that sorts values by a tuple of two keys:</p>
<div class="fragment"><div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;int&gt;</a>    keys1(ctx, n);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;float&gt;</a>  keys2(ctx, n);</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> vals (ctx, n);</div>
<div class="line"></div>
<div class="line"><span class="keyword">struct </span>{</div>
<div class="line">    <a class="code" href="operations_8hpp.html#aff85c71f5e6716591cf5948f92e093b3">VEX_FUNCTION</a>(device, <span class="keywordtype">bool</span>(<span class="keywordtype">int</span>, <span class="keywordtype">float</span>, <span class="keywordtype">int</span>, <span class="keywordtype">float</span>),</div>
<div class="line">            <span class="stringliteral">&quot;return (prm1 == prm3) ? (prm2 &lt; prm4) : (prm1 &lt; prm3);&quot;</span></div>
<div class="line">            );</div>
<div class="line">    <span class="keywordtype">bool</span> operator()(<span class="keywordtype">int</span> a1, <span class="keywordtype">float</span> a2, <span class="keywordtype">int</span> b1, <span class="keywordtype">float</span> b2)<span class="keyword"> const </span>{</div>
<div class="line">        <span class="keywordflow">return</span> std::make_tuple(a1, a2) &lt; std::tuple(b1, b2);</div>
<div class="line">    }</div>
<div class="line">} comp;</div>
<div class="line"></div>
<div class="line"><a class="code" href="namespacevex.html#a6c0d7aa078f1ae079e3a06708d9b84b6">vex::sort_by_key</a>(<a class="code" href="namespacevex.html#ab7ed95396644bcef1aff9a0cac89e69a">std::tie</a>(keys1, keys2), vals, comp);</div>
</div><!-- fragment --><h2><a class="anchor" id="multivectors"></a>Multivectors</h2>
<p>The class template <code><a class="el" href="classvex_1_1multivector.html" title="Container for several vex::vectors. ">vex::multivector</a>&lt;T,N&gt;</code> allows one to store several equally sized device vectors and perform computations on all components synchronously. Each operation is delegated to the underlying vectors, but usually results in the launch of a single fused kernel. Expressions may include values of <code>std::array&lt;T,N&gt;</code> type, where N is equal to the number of multivector components. Each component gets the corresponding element of <code>std::array&lt;&gt;</code> when the expression is applied. Similarly, the array subscript operator or reduction of a multivector returns an <code>std::array&lt;T,N&gt;</code>. In order to access k-th component of a multivector, one can use the overloaded <code>operator()</code>:</p>
<div class="fragment"><div class="line"><a class="code" href="operations_8hpp.html#aff85c71f5e6716591cf5948f92e093b3">VEX_FUNCTION</a>(between, <span class="keywordtype">bool</span>(<span class="keywordtype">double</span>, <span class="keywordtype">double</span>, <span class="keywordtype">double</span>), <span class="stringliteral">&quot;return prm1 &lt;= prm2 &amp;&amp; prm2 &lt;= prm3;&quot;</span>);</div>
<div class="line"></div>
<div class="line"><a class="code" href="classvex_1_1Reductor.html">vex::Reductor&lt;double, vex::SUM&gt;</a> sum(ctx);</div>
<div class="line"><a class="code" href="classvex_1_1SpMat.html">vex::SpMat&lt;double&gt;</a> A(ctx, ... );</div>
<div class="line">std::array&lt;double, 2&gt; v = {6.0, 7.0};</div>
<div class="line"></div>
<div class="line"><a class="code" href="classvex_1_1multivector.html">vex::multivector&lt;double, 2&gt;</a> X(ctx, N), Y(ctx, N);</div>
<div class="line"></div>
<div class="line"><span class="comment">// ...</span></div>
<div class="line"></div>
<div class="line">X = <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(v * Y + 1);             <span class="comment">// X(k) = sin(v[k] * Y(k) + 1);</span></div>
<div class="line">v = sum( between(0, X, Y) );    <span class="comment">// v[k] = sum( between( 0, X(k), Y(k) ) );</span></div>
<div class="line">X = A * Y;                      <span class="comment">// X(k) = A * Y(k);</span></div>
</div><!-- fragment --><p>Some operations can not be expressed with simple multivector arithmetic. For example, an operation of two dimensional rotation mixes components in the right hand side expressions: </p>
<div class="fragment"><div class="line">y0 = x0 * <a class="code" href="group__builtins.html#ga1c4f595ebe70270518a9925ff8c3b22f">cos</a>(alpha) - x1 * <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(alpha);</div>
<div class="line">y1 = x0 * <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(alpha) + x1 * <a class="code" href="group__builtins.html#ga1c4f595ebe70270518a9925ff8c3b22f">cos</a>(alpha);</div>
</div><!-- fragment --><p>This may in principle be implemented as: </p>
<div class="fragment"><div class="line"><span class="keywordtype">double</span> alpha;</div>
<div class="line"><a class="code" href="classvex_1_1multivector.html">vex::multivector&lt;double, 2&gt;</a> X(ctx, N), Y(ctx, N);</div>
<div class="line"></div>
<div class="line">Y(0) = X(0) * <a class="code" href="group__builtins.html#ga1c4f595ebe70270518a9925ff8c3b22f">cos</a>(alpha) - X(1) * <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(alpha);</div>
<div class="line">Y(1) = X(0) * <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(alpha) + X(1) * <a class="code" href="group__builtins.html#ga1c4f595ebe70270518a9925ff8c3b22f">cos</a>(alpha);</div>
</div><!-- fragment --><p> But this would result in two kernel launches. VexCL allows one to assign a tuple of expressions to a multivector, which will lead to the launch of a single fused kernel: </p>
<div class="fragment"><div class="line">Y = <a class="code" href="namespacevex.html#ab7ed95396644bcef1aff9a0cac89e69a">std::tie</a>( X(0) * <a class="code" href="group__builtins.html#ga1c4f595ebe70270518a9925ff8c3b22f">cos</a>(alpha) - X(1) * <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(alpha),</div>
<div class="line">              X(0) * <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(alpha) + X(1) * <a class="code" href="group__builtins.html#ga1c4f595ebe70270518a9925ff8c3b22f">cos</a>(alpha) );</div>
</div><!-- fragment --><h2><a class="anchor" id="converting-generic-c-algorithms-to-opencl"></a>Converting generic C++ algorithms to OpenCL/CUDA</h2>
<p>CUDA and OpenCL differ in their handling of compute kernels compilation. In NVIDIA's framework the compute kernels are compiled to PTX code together with the host program. In OpenCL the compute kernels are compiled at runtime from high-level C-like sources, adding an overhead which is particularly noticeable for smaller sized problems. This distinction leads to higher initialization cost of OpenCL programs, but at the same time it allows one to generate better optimized kernels for the problem at hand. VexCL exploits this possibility with help of its kernel generator mechanism. Moreover, VexCL's CUDA backend uses the same technique to generate and compile CUDA kernels at runtime.</p>
<p>An instance of <code>vex::symbolic&lt;T&gt;</code> dumps to an output stream any arithmetic operations it is being subjected to. For example, this code snippet: </p>
<div class="fragment"><div class="line">vex::symbolic&lt;double&gt; x = 6, y = 7;</div>
<div class="line">x = <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(x * y);</div>
</div><!-- fragment --><p> results in the following output: </p>
<div class="fragment"><div class="line"><span class="keywordtype">double</span> var1 = 6;</div>
<div class="line"><span class="keywordtype">double</span> var2 = 7;</div>
<div class="line">var1 = <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>( ( var1 * var2 ) );</div>
</div><!-- fragment --><h3><a class="anchor" id="kernel-generator"></a>Kernel generator</h3>
<p>The symbolic type allows one to record a sequence of arithmetic operations made by a generic C++ algorithm. To illustrate the idea, consider the generic implementation of a 4th order Runge-Kutta ODE stepper: </p>
<div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> state_type, <span class="keyword">class</span> SysFunction&gt;</div>
<div class="line"><span class="keywordtype">void</span> runge_kutta_4(SysFunction sys, state_type &amp;x, <span class="keywordtype">double</span> dt) {</div>
<div class="line">    state_type k1 = dt * sys(x);</div>
<div class="line">    state_type k2 = dt * sys(x + 0.5 * k1);</div>
<div class="line">    state_type k3 = dt * sys(x + 0.5 * k2);</div>
<div class="line">    state_type k4 = dt * sys(x + k3);</div>
<div class="line"></div>
<div class="line">    x += (k1 + 2 * k2 + 2 * k3 + k4) / 6;</div>
<div class="line">}</div>
</div><!-- fragment --><p> This function takes a system function <code>sys</code>, state variable <code>x</code>, and advances <code>x</code> by time step <code>dt</code>. For example, to model the equation <code>dx/dt = sin(x)</code>, one has to provide the following system function: </p>
<div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> state_type&gt;</div>
<div class="line">state_type sys_func(<span class="keyword">const</span> state_type &amp;x) {</div>
<div class="line">    <span class="keywordflow">return</span> <a class="code" href="group__builtins.html#gafb1ec8a36853de1b26d9667090dc3267">sin</a>(x);</div>
<div class="line">}</div>
</div><!-- fragment --><p>The following code snippet makes one hundred RK4 iterations for a single <code>double</code> value on a CPU: </p>
<div class="fragment"><div class="line"><span class="keywordtype">double</span> x = 1, dt = 0.01;</div>
<div class="line"></div>
<div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">int</span> <a class="code" href="group__builtins.html#ga7f6cbd5504c78c65ca481cef6471ad09">step</a> = 0; <a class="code" href="group__builtins.html#ga7f6cbd5504c78c65ca481cef6471ad09">step</a> &lt; 100; ++<a class="code" href="group__builtins.html#ga7f6cbd5504c78c65ca481cef6471ad09">step</a>)</div>
<div class="line">    runge_kutta_4(sys_func&lt;double&gt;, x, dt);</div>
</div><!-- fragment --><p>Let's now generate the kernel for a single RK4 step and apply the kernel to a <code><a class="el" href="classvex_1_1vector.html" title="Device vector. ">vex::vector</a>&lt;double&gt;</code> (by doing this we essentially simultaneously solve a large number of identical ODEs with different initial conditions). </p>
<div class="fragment"><div class="line"><span class="comment">// Set recorder for expression sequence.</span></div>
<div class="line">std::ostringstream body;</div>
<div class="line"><a class="code" href="namespacevex_1_1generator.html#a7bb760db4db25175da29d869f9b347d1">vex::generator::set_recorder</a>(body);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Create symbolic variable.</span></div>
<div class="line"><span class="keyword">typedef</span> vex::symbolic&lt;double&gt; sym_state;</div>
<div class="line">sym_state sym_x(sym_state::VectorParameter);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Record expression sequience for a single RK4 step.</span></div>
<div class="line"><span class="keywordtype">double</span> dt = 0.01;</div>
<div class="line">runge_kutta_4(sys_func&lt;sym_state&gt;, sym_x, dt);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Build kernel from the recorded sequence.</span></div>
<div class="line"><span class="keyword">auto</span> kernel = <a class="code" href="namespacevex_1_1generator.html#a4c60e9f68a2e74de54a073730704532e">vex::generator::build_kernel</a>(ctx, <span class="stringliteral">&quot;rk4_stepper&quot;</span>, body.str(), sym_x);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Create initial state.</span></div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> n = 1024 * 1024;</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> x(ctx, n);</div>
<div class="line">x = 10.0 * <a class="code" href="namespacevex.html#acf35349b5accc05f96b291457f522acb">vex::element_index</a>() / n;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Make 100 RK4 steps.</span></div>
<div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; 100; i++) kernel(x);</div>
</div><!-- fragment --><p>This approach has some obvious restrictions. Namely, the C++ code has to be embarrassingly parallel and is not allowed to contain any branching or data-dependent loops. Nevertheless, the kernel generation facility may save a substantial amount of both human and machine time when applicable.</p>
<h3><a class="anchor" id="function-generator"></a>Function generator</h3>
<p>VexCL also provides a user-defined function generator which takes a function signature and generic function object, and returns custom VexCL function ready to be used in vector expressions. Let's rewrite the above example using an autogenerated function for a Runge-Kutta stepper. First, we need to implement generic functor:</p>
<div class="fragment"><div class="line"><span class="keyword">struct </span>rk4_stepper {</div>
<div class="line">    <span class="keywordtype">double</span> dt;</div>
<div class="line"></div>
<div class="line">    rk4_stepper(<span class="keywordtype">double</span> dt) : dt(dt) {}</div>
<div class="line"></div>
<div class="line">    <span class="keyword">template</span> &lt;<span class="keyword">class</span> state_type&gt;</div>
<div class="line">    state_type operator()(<span class="keyword">const</span> state_type &amp;x)<span class="keyword"> const </span>{</div>
<div class="line">        state_type new_x = x;</div>
<div class="line">        runge_kutta_4(sys_func&lt;state_type&gt;, new_x, dt);</div>
<div class="line">        <span class="keywordflow">return</span> new_x;</div>
<div class="line">    }</div>
<div class="line">};</div>
</div><!-- fragment --><p>Now we can generate and apply the custom function: </p>
<div class="fragment"><div class="line"><span class="keywordtype">double</span> dt = 0.01;</div>
<div class="line">rk4_stepper stepper(dt);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Generate custom VexCL function:</span></div>
<div class="line"><span class="keyword">auto</span> rk4 = vex::generator::make_function&lt;double(double)&gt;(stepper);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Create initial state.</span></div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> n = 1024 * 1024;</div>
<div class="line"><a class="code" href="classvex_1_1vector.html">vex::vector&lt;double&gt;</a> x(ctx, n);</div>
<div class="line">x = 10.0 * <a class="code" href="namespacevex.html#acf35349b5accc05f96b291457f522acb">vex::element_index</a>() / n;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Use the function to advance initial state:</span></div>
<div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; 100; i++) x = rk4(x);</div>
</div><!-- fragment --><p>Note that both <code>runge_kutta_4()</code> and <code>rk4_stepper</code> may be reused for host-side computations.</p>
<p>It is very easy to generate a VexCL function from a Boost.Phoenix lambda expression (since Boost.Phoenix lambdas are themselves generic functors):</p>
<div class="fragment"><div class="line"><span class="keyword">using namespace </span>boost::phoenix::arg_names;</div>
<div class="line"><span class="keyword">using</span> <a class="code" href="namespacevex_1_1generator.html#af0263b233e113206855f28eb745b7ec8">vex::generator::make_function</a>;</div>
<div class="line"></div>
<div class="line"><span class="keyword">auto</span> squared_radius = make_function&lt;double(double, double)&gt;(arg1 * arg1 + arg2 * arg2);</div>
<div class="line"></div>
<div class="line">Z = squared_radius(X, Y);</div>
</div><!-- fragment --><h2><a class="anchor" id="custom-kernels"></a>Custom kernels</h2>
<p>As <a href="http://en.wikipedia.org/wiki/Kozma_Prutkov">Kozma Prutkov</a> repeatedly said, "One cannot embrace the unembraceable". So in order to be usable, VexCL has to support custom kernels. <code>vex::vector::operator()(uint k)</code> returns a <code>cl::Buffer</code> that holds vector data on the k-th compute device. If the result depends on the neighboring points, one has to keep in mind that these points are possibly located on a different compute device. In this case the exchange of these halo points has to be addressed manually.</p>
<p>The following example builds and launches a custom kernel for each device in the context: </p>
<div class="fragment"><div class="line">std::vector&lt;vex::backend::kernel&gt; kernel;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Compile and store the kernels for later use.</span></div>
<div class="line"><span class="keywordflow">for</span>(uint d = 0; d &lt; ctx.size(); d++) {</div>
<div class="line">    kernel.emplace_back(ctx.queue(d),</div>
<div class="line">        <a class="code" href="operations_8hpp.html#a8c4fa42e03a69b51b7e1af1c59a9a3b9">VEX_STRINGIZE_SOURCE</a>(</div>
<div class="line">            kernel <span class="keywordtype">void</span> dummy(ulong n, global <span class="keywordtype">float</span> *x) {</div>
<div class="line">                <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> i = get_global_id(0); i &lt; n; i += get_global_size(0))</div>
<div class="line">                    x[i] = 4.2;</div>
<div class="line">            }</div>
<div class="line">            ),</div>
<div class="line">        <span class="stringliteral">&quot;dummy&quot;</span></div>
<div class="line">        );</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="comment">// Apply the kernels to the vector partitions on each device.</span></div>
<div class="line"><span class="keywordflow">for</span>(uint d = 0; d &lt; ctx.size(); d++) {</div>
<div class="line">    kernel[d].push_arg&lt;cl_ulong&gt;(x.part_size());</div>
<div class="line">    kernel[d].push_arg(x(d));</div>
<div class="line"></div>
<div class="line">    kernel[d](ctx.queue(d));</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="interoperability-with-other-libraries"></a>Interoperability with other libraries</h2>
<p>Since VexCL is built upon standard Khronos OpenCL C++ bindings, it is easily interoperable with other OpenCL libraries. In particular, VexCL provides some glue code for <a href="http://viennacl.sourceforge.net/">ViennaCL</a> and for <a href="https://github.com/kylelutz/compute">Boost.compute</a> libraries.</p>
<p><a href="http://viennacl.sourceforge.net/">ViennaCL</a> (The Vienna Computing Library) is a scientific computing library written in C++. It provides OpenCL, CUDA, and OpenMP compute backends. The programming interface is compatible with Boost.uBLAS and allows for simple, high-level access to the vast computing resources available on parallel architectures such as GPUs. The library's primary focus is on common linear algebra operations (BLAS levels 1, 2 and 3) and the solution of large sparse systems of equations by means of iterative methods with optional preconditioners.</p>
<p>It is possible to use ViennaCL's generic solvers with VexCL types. See <a href="https://github.com/ddemidov/vexcl/blob/master/examples/viennacl/solvers.cpp">examples/viennacl/solvers.cpp</a> for an example.</p>
<p><a href="https://github.com/kylelutz/compute">Boost.compute</a> is a GPU/parallel-computing library for C++ based on OpenCL. The core library is a thin C++ wrapper over the OpenCL C API and provides access to compute devices, contexts, command queues and memory buffers. On top of the core library is a generic, STL-like interface providing common algorithms (e.g. <code>transform()</code>, <code>accumulate()</code>, <code><a class="el" href="namespacevex.html#a0ee2afe5ab14567e3900ecea19e46c78" title="Sort. ">sort()</a></code>) along with common containers (e.g. <code>vector&lt;T&gt;</code>, <code>flat_set&lt;T&gt;</code>). It also features a number of extensions including parallel-computing algorithms (e.g. <code>exclusive_scan()</code>, <code>scatter()</code>, <code><a class="el" href="namespacevex.html#ab9f2a40c6b7a0f4b540ba12f2b52532b" title="Reduce vex::multi_array along the specified dimensions. ">reduce()</a></code>) and a number of fancy iterators (e.g. <code>transform_iterator&lt;&gt;</code>, <code>permutation_iterator&lt;&gt;</code>, <code>zip_iterator&lt;&gt;</code>).</p>
<p><a href="https://github.com/ddemidov/vexcl/blob/master/vexcl/external/boost_compute.hpp">vexcl/external/boost_compute.hpp</a> provides an example of using Boost.compute algorithms with VexCL vectors. Namely, it implements parallel sort and inclusive scan primitives on top of the corresponding Boost.compute algorithms.</p>
<h2><a class="anchor" id="supported-compilers"></a>Supported compilers</h2>
<p>VexCL makes heavy use of C++11 features, so your compiler has to be modern enough. The compilers that have been tested and supported:</p>
<ul>
<li>GCC v4.6 and higher.</li>
<li>Clang v3.1 and higher.</li>
<li>Microsoft Visual C++ 2010 and higher.</li>
</ul>
<p>VexCL uses standard OpenCL bindings for C++ from Khronos group. The cl.hpp file should be included with the OpenCL implementation on your system, but it is also provided with the library. </p>
<hr/>
<p> <em>This work is a joint effort of <a href="http://www.jscc.ru/eng/index.shtml">Supercomputer Center of Russian Academy of Sciences</a> (Kazan branch) and <a href="http://www.kpfu.ru">Kazan Federal University</a>. It is partially supported by RFBR grants No 12-07-0007 and 12-01-00333a.</em> </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.5
</small></address>
</body>
</html>
